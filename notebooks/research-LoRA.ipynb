{
 "cells": [
  {
   "cell_type": "raw",
   "id": "24a5f5d0-c1d1-425c-b39b-36f4057c32e9",
   "metadata": {},
   "source": [
    "!pip install --upgrade accelerate\n",
    "!pip uninstall -y transformers accelerate\n",
    "!pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abcd66a5-7ff7-4277-a900-a2451c2ed1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import tempfile\n",
    "import logging\n",
    "import random\n",
    "import config\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "\n",
    "#from utilities import *\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForCausalLM\n",
    "from llama import BasicModelRunner\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "logger = logging.getLogger(__name__)\n",
    "global_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b34913-5333-4d4e-8a64-9fa4bcb5b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "from transformers.trainer_callback import TrainerCallback\n",
    "from transformers import BitsAndBytesConfig\n",
    "from trl import SFTTrainer\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626c55c-70d2-4c9f-a595-0e09bcbd8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 's2e-lab/RegexEval'\n",
    "model_name = 'openlm-research/open_llama_3b_v2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67062a33-49bd-40ae-8696-2a5fd2206524",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = load_dataset('s2e-lab/RegexEval', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53ada2b-4654-4bca-b1d1-aef2b5c9bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "instruction_dataset_df = pd.DataFrame(raw_dataset)\n",
    "instruction_dataset_dict = instruction_dataset_df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e8acad-e976-4e61-93af-78687fb7e978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expression</th>\n",
       "      <th>raw_prompt</th>\n",
       "      <th>refined_prompt</th>\n",
       "      <th>matches</th>\n",
       "      <th>non_matches</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>^\\d$</td>\n",
       "      <td>Matches exactly 1 numeric digit (0-9).</td>\n",
       "      <td>Matches exactly 1 numeric digit (0-9).\\nMatch ...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 0]</td>\n",
       "      <td>[a, 324, num, location = 3, ssda, 11, hello wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>^\\d{5}$</td>\n",
       "      <td>Matches 5 numeric digits, such as a zip code.</td>\n",
       "      <td>Matches 5 numeric digits, such as a zip code.\\...</td>\n",
       "      <td>[33333, 55555, 23445, 89343, 46556, 25432, 253...</td>\n",
       "      <td>[abcd, 1324, as;lkjdf, jaldks, 234, 8hr4f, fsd...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  expression                                     raw_prompt  \\\n",
       "0       ^\\d$         Matches exactly 1 numeric digit (0-9).   \n",
       "1    ^\\d{5}$  Matches 5 numeric digits, such as a zip code.   \n",
       "\n",
       "                                      refined_prompt  \\\n",
       "0  Matches exactly 1 numeric digit (0-9).\\nMatch ...   \n",
       "1  Matches 5 numeric digits, such as a zip code.\\...   \n",
       "\n",
       "                                             matches  \\\n",
       "0                     [1, 2, 3, 4, 5, 6, 7, 8, 9, 0]   \n",
       "1  [33333, 55555, 23445, 89343, 46556, 25432, 253...   \n",
       "\n",
       "                                         non_matches  id  \n",
       "0  [a, 324, num, location = 3, ssda, 11, hello wo...   1  \n",
       "1  [abcd, 1324, as;lkjdf, jaldks, 234, 8hr4f, fsd...   2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction_dataset_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e7e7118-27ac-4549-8c51-6de05b48a69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction_dataset_df['refined_prompt'].apply(lambda x: len(x.split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b324d-a0ce-4308-a169-86a6c86f3593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the two attributes into an instruction string\n",
    "rd_df['instruction'] = 'Create a detailed description for the following product: '+ rd_df['product']+', belonging to category: '+ rd_df['category']\n",
    "\n",
    "rd_df = rd_df[['instruction', 'description']]\n",
    "\n",
    "#Get a 5000 sample subset for fine-tuning purposes\n",
    "rd_df_sample = rd_df.sample(n=5000, random_state=42)\n",
    "\n",
    "#Define template and format data into the template for supervised fine-tuning\n",
    "template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "\n",
    "{}\n",
    "\n",
    "### Response:\\n\"\"\"\n",
    "\n",
    "rd_df_sample['prompt'] = rd_df_sample[\"instruction\"].apply(lambda x: template.format(x))\n",
    "rd_df_sample.rename(columns={'description': 'response'}, inplace=True)\n",
    "rd_df_sample['response'] = rd_df_sample['response'] + \"\\n### End\"\n",
    "rd_df_sample = rd_df_sample[['prompt', 'response']]\n",
    "\n",
    "rd_df_sample['text'] = rd_df_sample[\"prompt\"] + rd_df_sample[\"response\"]\n",
    "rd_df_sample.drop(columns=['prompt', 'response'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bbd432d-9b37-43ad-9140-643af248adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_finetuning_dataset(dataset_dict: dict, question_key: str, answer_key: str) -> Dataset:\n",
    "    instruction_template = \"\"\"### Generate a regex for this description:\n",
    "    {question}\n",
    "    \n",
    "    ### Answer:\"\"\"\n",
    "\n",
    "    prompt_template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "    ### Instruction:\n",
    "    \n",
    "    {instruction}\n",
    "    \n",
    "    ### Response:\\n\"\"\"\n",
    "    \n",
    "    num_samples = len(dataset_dict[question_key])\n",
    "    finetuning_dataset_list = []\n",
    "    for i in range(num_samples):\n",
    "        question = dataset_dict[question_key][i]\n",
    "        instruction = instruction_template.format(question=question)\n",
    "        prompt = prompt_template.format(instruction=instruction)\n",
    "        response = dataset_dict[answer_key][i] + \"\\n### End\"\n",
    "        text = prompt + response\n",
    "        finetuning_dataset_list.append({\"instruction\": instruction, \"response\": answer, \"text\": text})\n",
    "\n",
    "    finetuning_dataset = Dataset.from_list(finetuning_dataset_list)\n",
    "\n",
    "    print(\"One datapoint in the finetuning dataset:\")\n",
    "    pprint(finetuning_dataset[0])\n",
    "    \n",
    "    return finetuning_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac0b73f7-c0d7-4a6d-b801-bd309453e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One datapoint in the finetuning dataset:\n",
      "{'answer': '^\\\\d$',\n",
      " 'question': '### Generate a regex for this description:\\n'\n",
      "             '    Matches exactly 1 numeric digit (0-9).\\n'\n",
      "             'Match examples:\\n'\n",
      "             '- \"1\"\\n'\n",
      "             '- \"2\"\\n'\n",
      "             '- \"3\"\\n'\n",
      "             'Non-match examples:\\n'\n",
      "             '- \"a\"\\n'\n",
      "             '- \"324\"\\n'\n",
      "             '    \\n'\n",
      "             '    ### Answer:'}\n"
     ]
    }
   ],
   "source": [
    "finetuning_dataset = form_finetuning_dataset(instruction_dataset_dict, question_key = \"refined_prompt\", answer_key = \"expression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56ed10cd-2acb-4228-b2c2-4052a443b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = finetuning_dataset.train_test_split(test_size=0.1, shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9fb48ed-d572-4464-9cb9-57b8443b99f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 685\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 77\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed15fc-fc10-4f48-84c6-ef8bf39312e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b0e65-fa28-4f42-ba3e-d388c917637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If only targeting attention blocks of the model\n",
    "target_modules = [\"q_proj\", \"v_proj\"]\n",
    "\n",
    "#If targeting all linear layers\n",
    "#target_modules = ['q_proj','k_proj','v_proj','o_proj','gate_proj','down_proj','up_proj','lm_head']\n",
    "\n",
    "lora_config = LoraConfig(r=16,\n",
    "                        target_modules = target_modules,\n",
    "                        lora_alpha=8,\n",
    "                        lora_dropout=0.05,\n",
    "                        bias=\"none\",\n",
    "                        task_type=\"CAUSAL_LM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d67e0b-f306-4ed2-aab5-8cad6a59b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_device_train_batch_size = 4\n",
    "gradient_accumulation_steps = 4\n",
    "optim = 'adamw_hf'\n",
    "learning_rate = 1e-5\n",
    "max_grad_norm = 0.3\n",
    "warmup_ratio = 0.03\n",
    "lr_scheduler_type = \"linear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08c0d5-7e4a-4b98-8b4f-2f412205d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"01-experiment\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs = 3.0,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    learning_rate=learning_rate,\n",
    "    fp16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c5d045-924e-46c1-a025-405163b2b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf4_config = BitsAndBytesConfig(\n",
    "  load_in_4bit=True,\n",
    "  bnb_4bit_quant_type=\"nf4\",\n",
    "  bnb_4bit_use_double_quant=True,\n",
    "  bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a529f1-2cc6-4b24-a795-100da7d3d06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 396/396 [00:00<?, ?B/s] \n",
      "Downloading tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 2.93MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 99.0/99.0 [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5995ad-dc01-4aba-8712-cfe7a9a79a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    model_name, device_map='auto', quantization_config=nf4_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ef728-f612-4dc5-9c33-2e9f3d7a6f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53c402-e69a-4f2e-841d-08af3c96d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=256,\n",
    "    args=training_args,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bbdae3-c232-4172-8815-4117921c4635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upcast layer norms to float 32 for stability\n",
    "for name, module in trainer.model.named_modules():\n",
    "  if \"norm\" in name:\n",
    "    module = module.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cf2842-12ad-479d-9458-b3322e5ebcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the training process\n",
    "with mlflow.start_run(run_name='01-LoRA-Experiment'):\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc1201-81b5-4ef7-b6e8-687766cc2ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefb5889-1ba5-48c6-b190-86521625e71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4dbf9c-d324-4412-b38d-83b76eb461da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b40ffe4-ecd5-44f3-891b-e9cb72126011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer\\\\tokenizer_config.json',\n",
       " 'tokenizer\\\\special_tokens_map.json',\n",
       " 'tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save tokenizer\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a49c138a-f0a0-4f3b-91fb-6cf68b04ae15",
   "metadata": {},
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d10e9522-50e3-40bc-b495-4829ef294e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "def generate_batch_sized_chunks(list_of_elements, batch_size):\n",
    "    \"\"\"split the dataset into smaller batches that we can process simultaneously\n",
    "    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def exact_match_ratio(predictions, references):\n",
    "    total_cases = len(predictions)\n",
    "    correct_cases = sum(1 for pred, ref in zip(predictions, references) if pred == ref)\n",
    "    return correct_cases / total_cases if total_cases > 0 else 0.0\n",
    "\n",
    "\n",
    "def calculate_metric_on_test_ds(dataset, model, tokenizer, \n",
    "                                batch_size=16, \n",
    "                                device=device, \n",
    "                                question_key=\"question\", \n",
    "                                answer_key=\"answer\"):\n",
    "                            \n",
    "    input_batches = list(generate_batch_sized_chunks(dataset[question_key], batch_size))\n",
    "    target_batches = list(generate_batch_sized_chunks(dataset[answer_key], batch_size))\n",
    "\n",
    "    predictions_batches = []\n",
    "    references_batches = []\n",
    "    for input_batches, target_batch in tqdm(zip(input_batches, target_batches), total=len(input_batches)):\n",
    "        \n",
    "        inputs = tokenizer(input_batches, \n",
    "                           max_length=128, \n",
    "                           truncation=True, \n",
    "                           padding=\"max_length\", \n",
    "                           return_tensors=\"pt\")\n",
    "        \n",
    "        regex = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                                 attention_mask=inputs[\"attention_mask\"].to(device), \n",
    "                                 num_beams=8, \n",
    "                                 max_length=512)\n",
    "        \n",
    "        decoded_regex = [tokenizer.decode(s, skip_special_tokens=True, clean_up_tokenization_spaces=True) for s in regex]      \n",
    "        \n",
    "        decoded_regex = [d.replace(\"\", \" \") for d in decoded_regex]\n",
    "        \n",
    "        predictions_batches.append(decoded_regex[0])\n",
    "        references_batches.append(target_batch[0])\n",
    "        \n",
    "\n",
    "    score = exact_match_ratio(predictions_batches, references_batches)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "28ab7ca7-3cb0-45ee-932c-a0da2133879b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 12%|█▎        | 1/8 [00:03<00:22,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 25%|██▌       | 2/8 [00:05<00:17,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 38%|███▊      | 3/8 [00:08<00:14,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 50%|█████     | 4/8 [00:11<00:11,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 62%|██████▎   | 5/8 [00:14<00:08,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 75%|███████▌  | 6/8 [00:16<00:05,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 88%|████████▊ | 7/8 [00:19<00:02,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "100%|██████████| 8/8 [00:22<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score = calculate_metric_on_test_ds(test_dataset[0:16],  \n",
    "                                    model=trainer.model, \n",
    "                                    tokenizer=tokenizer, \n",
    "                                    batch_size = 2, \n",
    "                                    question_key='question', \n",
    "                                    answer_key='answer')\n",
    "\n",
    "\n",
    "print(\"Exact matches persentage: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac5884-d6fb-449b-8214-a9b927601e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
