{
 "cells": [
  {
   "cell_type": "raw",
   "id": "24a5f5d0-c1d1-425c-b39b-36f4057c32e9",
   "metadata": {},
   "source": [
    "!pip install --upgrade accelerate\n",
    "!pip uninstall -y transformers accelerate\n",
    "!pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abcd66a5-7ff7-4277-a900-a2451c2ed1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import tempfile\n",
    "import logging\n",
    "import random\n",
    "import config\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "\n",
    "#from utilities import *\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import TrainingArguments\n",
    "from transformers import AutoModelForCausalLM\n",
    "from llama import BasicModelRunner\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "logger = logging.getLogger(__name__)\n",
    "global_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2beb19d2-bfe0-48d8-bd3e-a201e87344a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_count = torch.cuda.device_count()\n",
    "if device_count > 0:\n",
    "    logger.debug(\"Select GPU device\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    logger.debug(\"Select CPU device\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67062a33-49bd-40ae-8696-2a5fd2206524",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('s2e-lab/RegexEval', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7853d538-6fbf-476e-aa7e-7e04d33c8a77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 567/567 [00:00<?, ?B/s] \n",
      "C:\\Users\\logis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\logis\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading model.safetensors: 100%|██████████| 166M/166M [00:24<00:00, 6.69MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(50304, 512)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=512, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_name = \"microsoft/phi-1_5\"\n",
    "model_name = \"EleutherAI/pythia-70m\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
    "base_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a529f1-2cc6-4b24-a795-100da7d3d06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 396/396 [00:00<?, ?B/s] \n",
      "Downloading tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 2.93MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 99.0/99.0 [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "#torch.set_default_device(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53ada2b-4654-4bca-b1d1-aef2b5c9bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "instruction_dataset_df = pd.DataFrame(dataset)\n",
    "instruction_dataset_dict = instruction_dataset_df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70e8acad-e976-4e61-93af-78687fb7e978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expression</th>\n",
       "      <th>raw_prompt</th>\n",
       "      <th>refined_prompt</th>\n",
       "      <th>matches</th>\n",
       "      <th>non_matches</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>^\\d$</td>\n",
       "      <td>Matches exactly 1 numeric digit (0-9).</td>\n",
       "      <td>Matches exactly 1 numeric digit (0-9).\\nMatch ...</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 0]</td>\n",
       "      <td>[a, 324, num, location = 3, ssda, 11, hello wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>^\\d{5}$</td>\n",
       "      <td>Matches 5 numeric digits, such as a zip code.</td>\n",
       "      <td>Matches 5 numeric digits, such as a zip code.\\...</td>\n",
       "      <td>[33333, 55555, 23445, 89343, 46556, 25432, 253...</td>\n",
       "      <td>[abcd, 1324, as;lkjdf, jaldks, 234, 8hr4f, fsd...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  expression                                     raw_prompt  \\\n",
       "0       ^\\d$         Matches exactly 1 numeric digit (0-9).   \n",
       "1    ^\\d{5}$  Matches 5 numeric digits, such as a zip code.   \n",
       "\n",
       "                                      refined_prompt  \\\n",
       "0  Matches exactly 1 numeric digit (0-9).\\nMatch ...   \n",
       "1  Matches 5 numeric digits, such as a zip code.\\...   \n",
       "\n",
       "                                             matches  \\\n",
       "0                     [1, 2, 3, 4, 5, 6, 7, 8, 9, 0]   \n",
       "1  [33333, 55555, 23445, 89343, 46556, 25432, 253...   \n",
       "\n",
       "                                         non_matches  id  \n",
       "0  [a, 324, num, location = 3, ssda, 11, hello wo...   1  \n",
       "1  [abcd, 1324, as;lkjdf, jaldks, 234, 8hr4f, fsd...   2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction_dataset_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e7e7118-27ac-4549-8c51-6de05b48a69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction_dataset_df['refined_prompt'].apply(lambda x: len(x.split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bbd432d-9b37-43ad-9140-643af248adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_finetuning_dataset(dataset_dict: dict, question_key: str, answer_key: str) -> Dataset:\n",
    "    prompt_template = \"\"\"### Generate a regex for this description:\n",
    "    {question}\n",
    "    \n",
    "    ### Answer:\"\"\"\n",
    "    \n",
    "    num_samples = len(dataset_dict[question_key])\n",
    "    finetuning_dataset_list = []\n",
    "    for i in range(num_samples):\n",
    "      question = dataset_dict[question_key][i]\n",
    "      answer = dataset_dict[answer_key][i]\n",
    "      text_with_prompt_template = prompt_template.format(question=question)\n",
    "      finetuning_dataset_list.append({\"question\": text_with_prompt_template, \"answer\": answer})\n",
    "\n",
    "    finetuning_dataset = Dataset.from_list(finetuning_dataset_list)\n",
    "\n",
    "    print(\"One datapoint in the finetuning dataset:\")\n",
    "    pprint(finetuning_dataset[0])\n",
    "    \n",
    "    return finetuning_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac0b73f7-c0d7-4a6d-b801-bd309453e90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One datapoint in the finetuning dataset:\n",
      "{'answer': '^\\\\d$',\n",
      " 'question': '### Generate a regex for this description:\\n'\n",
      "             '    Matches exactly 1 numeric digit (0-9).\\n'\n",
      "             'Match examples:\\n'\n",
      "             '- \"1\"\\n'\n",
      "             '- \"2\"\\n'\n",
      "             '- \"3\"\\n'\n",
      "             'Non-match examples:\\n'\n",
      "             '- \"a\"\\n'\n",
      "             '- \"324\"\\n'\n",
      "             '    \\n'\n",
      "             '    ### Answer:'}\n"
     ]
    }
   ],
   "source": [
    "finetuning_dataset = form_finetuning_dataset(instruction_dataset_dict, question_key = \"refined_prompt\", answer_key = \"expression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f82b44b-4c99-4fe8-a71b-101931e1dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(example_batch):\n",
    "    input_encodings = tokenizer(example_batch['question'] , max_length = 128, truncation = True, padding='max_length')\n",
    "    \n",
    "    target_encodings = tokenizer(example_batch['answer'], max_length = 128, truncation = True, padding='max_length')\n",
    "        \n",
    "    return {\n",
    "        'input_ids' : input_encodings['input_ids'],\n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'labels': target_encodings['input_ids']\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7259d75-95d3-447c-afc5-055af79051de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 762/762 [00:00<00:00, 3734.51 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = finetuning_dataset.map(convert_examples_to_features, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56ed10cd-2acb-4228-b2c2-4052a443b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9fb48ed-d572-4464-9cb9-57b8443b99f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 685\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 77\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a38d8f5-4e69-4032-8029-6dbe520a79df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = split_dataset['train']\n",
    "test_dataset = split_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b20da02c-d86a-4d3f-b9c4-4997b43f1642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=base_model, padding=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fa8ccc0-76c8-4e98-8f40-063cb12d06cf",
   "metadata": {},
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"test-trainer\",\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd76b82b-39bb-48f0-8495-2a0f741a4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test-trainer\", num_train_epochs=1, warmup_steps=500,\n",
    "    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01, logging_steps=10,\n",
    "    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n",
    "    gradient_accumulation_steps=16\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "185250ff-ee34-43a7-a940-041654b4721b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 07:41, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=42, training_loss=6.863502139136905, metrics={'train_runtime': 473.2012, 'train_samples_per_second': 1.448, 'train_steps_per_second': 0.089, 'total_flos': 23054512029696.0, 'train_loss': 6.863502139136905, 'epoch': 0.98})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    base_model,\n",
    "    training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e185a11-d6bb-484e-ae77-f41efa7d8262",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save model\n",
    "base_model.save_pretrained(\"pythia-tuned-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b40ffe4-ecd5-44f3-891b-e9cb72126011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer\\\\tokenizer_config.json',\n",
       " 'tokenizer\\\\special_tokens_map.json',\n",
       " 'tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save tokenizer\n",
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a49c138a-f0a0-4f3b-91fb-6cf68b04ae15",
   "metadata": {},
   "source": [
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d10e9522-50e3-40bc-b495-4829ef294e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "def generate_batch_sized_chunks(list_of_elements, batch_size):\n",
    "    \"\"\"split the dataset into smaller batches that we can process simultaneously\n",
    "    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def exact_match_ratio(predictions, references):\n",
    "    total_cases = len(predictions)\n",
    "    correct_cases = sum(1 for pred, ref in zip(predictions, references) if pred == ref)\n",
    "    return correct_cases / total_cases if total_cases > 0 else 0.0\n",
    "\n",
    "\n",
    "def calculate_metric_on_test_ds(dataset, model, tokenizer, \n",
    "                                batch_size=16, \n",
    "                                device=device, \n",
    "                                question_key=\"question\", \n",
    "                                answer_key=\"answer\"):\n",
    "                            \n",
    "    input_batches = list(generate_batch_sized_chunks(dataset[question_key], batch_size))\n",
    "    target_batches = list(generate_batch_sized_chunks(dataset[answer_key], batch_size))\n",
    "\n",
    "    predictions_batches = []\n",
    "    references_batches = []\n",
    "    for input_batches, target_batch in tqdm(zip(input_batches, target_batches), total=len(input_batches)):\n",
    "        \n",
    "        inputs = tokenizer(input_batches, \n",
    "                           max_length=128, \n",
    "                           truncation=True, \n",
    "                           padding=\"max_length\", \n",
    "                           return_tensors=\"pt\")\n",
    "        \n",
    "        regex = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                                 attention_mask=inputs[\"attention_mask\"].to(device), \n",
    "                                 num_beams=8, \n",
    "                                 max_length=512)\n",
    "        \n",
    "        decoded_regex = [tokenizer.decode(s, skip_special_tokens=True, clean_up_tokenization_spaces=True) for s in regex]      \n",
    "        \n",
    "        decoded_regex = [d.replace(\"\", \" \") for d in decoded_regex]\n",
    "        \n",
    "        predictions_batches.append(decoded_regex[0])\n",
    "        references_batches.append(target_batch[0])\n",
    "        \n",
    "\n",
    "    score = exact_match_ratio(predictions_batches, references_batches)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "28ab7ca7-3cb0-45ee-932c-a0da2133879b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      " 12%|█▎        | 1/8 [00:03<00:22,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 25%|██▌       | 2/8 [00:05<00:17,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 38%|███▊      | 3/8 [00:08<00:14,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 50%|█████     | 4/8 [00:11<00:11,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 62%|██████▎   | 5/8 [00:14<00:08,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 75%|███████▌  | 6/8 [00:16<00:05,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      " 88%|████████▊ | 7/8 [00:19<00:02,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "100%|██████████| 8/8 [00:22<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "score = calculate_metric_on_test_ds(test_dataset[0:16],  \n",
    "                                    model=trainer.model, \n",
    "                                    tokenizer=tokenizer, \n",
    "                                    batch_size = 2, \n",
    "                                    question_key='question', \n",
    "                                    answer_key='answer')\n",
    "\n",
    "\n",
    "print(\"Exact matches persentage: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac5884-d6fb-449b-8214-a9b927601e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
