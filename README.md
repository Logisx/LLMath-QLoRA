![Logo](https://github.com/Logisx/LLMath-QLoRA/blob/main/assets/logo-color-cropped.png?raw=true)

# :page_facing_up: Table of Contents 

- [:page\_facing\_up: Table of Contents](#page_facing_up-table-of-contents)
- [:rocket: LLM Instruction tuning for school math questions](#rocket-llm-instruction-tuning-for-school-math-questions)
  - [:bar\_chart: Model \& Dataset](#bar_chart-model--dataset)
  - [:toolbox: Tech Stack](#toolbox-tech-stack)
  - [:file\_folder: Project structure](#file_folder-project-structure)
  - [:computer: Run Locally](#computer-run-locally)
- [:world\_map: Roadmap](#world_map-roadmap)
- [‚öñÔ∏è License](#Ô∏è-license)
- [üîó Links](#-links)
- [References \& Citations](#references--citations)
# :rocket: LLM Instruction tuning for school math questions

End-to-end MLOps project for LLM instruction finetuning based on PEFT & QLoRA to optimize the training.

![Python](https://img.shields.io/badge/Python-3.11-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.1.1-purple)
![JupyterLab](https://img.shields.io/badge/Jupyter%20Lab-Research-orange)
![Transformers](https://img.shields.io/badge/Transformers-NLP-amber)
![Docker](https://img.shields.io/badge/Docker-Container-blue)
![DVC](https://img.shields.io/badge/DVC-Version%20Control-ee4d5f)
![MLflow](https://img.shields.io/badge/MLflow-Tracking-brightgreen)
![FastAPI](https://img.shields.io/badge/FastAPI-API-009688)
![AWS](https://img.shields.io/badge/AWS-Cloud%20Deployment-FF9900)
![CI/CD](https://img.shields.io/badge/CI%2FCD-Workflow-4D7A97)
[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/) 


![Demo](https://github.com/Logisx/IELTS-Grading/blob/main/assets/Demo.gif?raw=true)


## :bar_chart: Model & Dataset
**Base LLM**: [OpenLLaMA](https://huggingface.co/openlm-research/open_llama_3b_v2)\
**Dataset**: [Grade School Math Instructions Dataset](https://huggingface.co/datasets/qwedsacf/grade-school-math-instructions)


## :toolbox: Tech Stack

- **NLP**: PyTorch, Jupyter Lab, Hugging Face Transformers, Accelerate, PEFT
- **Framework**: FastApi
- **Deployment**: Docker, Amazon Web Services (AWS), GitHub Actions
- **Version Control**: Git, DVC, GitHub
- **Testing**: REST client

## :file_folder: Project structure
Project structure template can be found [here](https://drivendata.github.io/cookiecutter-data-science/)
```
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ Makefile                  <- Makefile with commands like `make data` or `make train`
‚îú‚îÄ‚îÄ README.md                 <- The top-level README for developers using this project.
‚îú‚îÄ‚îÄ requirements.txt          <- The requirements file for reproducing the analysis environment, e.g.
‚îÇ                                 generated with `pip freeze > requirements.txt`
|
‚îú‚îÄ‚îÄ config                    <- Stores pipelines' configuration files
|   ‚îú‚îÄ‚îÄ data-config.yaml
|   ‚îú‚îÄ‚îÄ model-config.yaml
|   ‚îî‚îÄ‚îÄ model-parameters.yaml
|
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ external              <- Data from third party sources.
‚îÇ   ‚îú‚îÄ‚îÄ interim               <- Intermediate data that has been transformed.
‚îÇ   ‚îú‚îÄ‚îÄ processed             <- The final, canonical data sets for modeling.
‚îÇ   ‚îî‚îÄ‚îÄ raw                   <- The original, immutable data dump.
‚îÇ
‚îú‚îÄ‚îÄ assets                    <- Store public assets for readme file
‚îú‚îÄ‚îÄ docs                      <- A default Sphinx project; see sphinx-doc.org for details
‚îÇ
‚îú‚îÄ‚îÄ models                    <- Trained and serialized models, model predictions, or model summaries
‚îÇ
‚îú‚îÄ‚îÄ notebooks                 <- Jupyter notebooks for research.
‚îÇ
‚îú‚îÄ‚îÄ setup.py                  <- Make this project pip installable with `pip install -e`
‚îú‚îÄ‚îÄ src                       <- Source code for use in this project.
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py           <- Makes src a Python module
‚îÇ   ‚îÇ
|   ‚îú‚îÄ‚îÄ logging               <- Define loggers for the app
|   ‚îú‚îÄ‚îÄ utils
|   |   ‚îú‚îÄ‚îÄ __init__.py
|   |   ‚îî‚îÄ‚îÄ common.py         <- Functions for common utilities
|   |
‚îÇ   ‚îú‚îÄ‚îÄ data                  <- Scripts to download or generate data
|   |   ‚îú‚îÄ‚îÄ components        <- Classes for pipelines
|   |   ‚îú‚îÄ‚îÄ pipeline          <- Scripts for data aggregation
|   |   ‚îú‚îÄ‚îÄ configuration.py  <- Class to manage config files
|   |   ‚îú‚îÄ‚îÄ entity.py         <- Stores configuration dataclasses
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ make_dataset.py   <- Script to run data pipelines
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ models                <- Scripts to train models and then use trained models to make
‚îÇ       ‚îÇ                         predictions
|       ‚îú‚îÄ‚îÄ components        <- Classes for pipelines
|       ‚îú‚îÄ‚îÄ pipeline          <- Scripts for data aggregation
|       ‚îú‚îÄ‚îÄ configuration.py  <- Class to manage config files
|       ‚îú‚îÄ‚îÄ entity.py         <- Stores configuration dataclasses
‚îÇ       ‚îú‚îÄ‚îÄ predict_model.py  <- Script to run prediction pipeline
‚îÇ       ‚îî‚îÄ‚îÄ train_model.py    <- Script to run model pipelines
‚îÇ
‚îú‚îÄ‚îÄ main.py                   <- Script to run model training pipeline
‚îú‚îÄ‚îÄ app.py                    <- Script to start FastApi app
|
‚îú‚îÄ‚îÄ .env.example              <- example .env structure
‚îú‚îÄ‚îÄ Dockerfile                <- configurates Docker container image
‚îú‚îÄ‚îÄ .github
|   ‚îî‚îÄ‚îÄ workflows
|       ‚îî‚îÄ‚îÄ main.yaml         <- CI/CD config 
|
‚îú‚îÄ‚îÄ .gitignore                <- specify files to be ignored by git
‚îú‚îÄ‚îÄ .dvcignore                <- specify files to be ignored by dvc
|
‚îú‚îÄ‚îÄ .dvc                      <- dvc config 
‚îú‚îÄ‚îÄ dvc.lock                  <- store dvc tracked information
‚îî‚îÄ‚îÄ dvc.yaml                  <- specify pipeline version control
```

## :computer: Run Locally

1. Clone the project

```bash
  git clone https://github.com/Logisx/LLMath-QLoRA
```

2. Go to the project directory

```bash
  cd my-project
```

3. Install dependencies

```bash
  pip install -r requirements.txt
```

4. Start the app

```bash
  python app.py
```

# :world_map: Roadmap

1. **Testing features**: Develop unit tests and integrations test.
2. **Data collection**: Aggregate more data to improve accuracy.
3. **Educational insights feature**: Along with the score, the application will offer insights and suggestions for improvement, making it a valuable educational tool for those looking to enhance their writing skills.


# ‚öñÔ∏è License

[MIT](https://github.com/Logisx/DeepEssay/blob/main/LICENSE)


# üîó Links
[![linkedin](https://img.shields.io/badge/linkedin-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/aleksandrshishkov)

# References & Citations